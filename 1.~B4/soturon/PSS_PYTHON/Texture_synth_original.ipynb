{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[PIL.PngImagePlugin] 2021-07-20 00:56:07,883 DEBUG 146 STREAM b'IHDR' 16 13\n",
      "[PIL.PngImagePlugin] 2021-07-20 00:56:07,884 DEBUG 146 STREAM b'IDAT' 41 8192\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.linalg import LinAlgError\n",
    "from scipy.stats import skew, kurtosis\n",
    "from PIL import Image\n",
    "import sys, os\n",
    "import logging\n",
    "import argparse, copy\n",
    "import time\n",
    "\n",
    "import sutils\n",
    "import steerable_pyramid_mat as steerable\n",
    "import texture_analysis_g as ta\n",
    "from scipy import io\n",
    "from IPython.core.debugger import Pdb\n",
    "from pandas import DataFrame as DF\n",
    "import openpyxl\n",
    "import pandas as pd\n",
    "\n",
    "#ALPHA = 0.8\n",
    "ALPHA = 0.0001\n",
    "'''\n",
    "\tTexture Synthesis by Portilla-Simoncelli's algorithm\n",
    "\n",
    "'''\n",
    "\n",
    "out_path =\"paper\"\n",
    "#out_path=\"tmp1999\"\n",
    "#image = Image.open(\"samples/blanket2-b-p017_original.png\").convert(\"L\")\n",
    "#image = Image.open(\"periodic/CountExamp1.o.jpg\").convert(\"L\")\n",
    "#image = Image.open(\"test2.png\").convert(\"L\")\n",
    "image = Image.open(\"paper_256_gray.png\").convert(\"L\")\n",
    "#image = Image.open(\"1999.png\").convert(\"L\")\n",
    "image = image.resize((256,256))\n",
    "\n",
    "image = np.array(image)\n",
    "\n",
    "resol_x = image.shape[1]\n",
    "resol_y = image.shape[0]\n",
    "num_depth = 4\n",
    "num_ori = 4\n",
    "num_neighbor = 7\n",
    "iter = 200\n",
    "\n",
    "cmask = np.array([1,1,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cmask (optional): binary column vector (4x1) indicating which sets of\n",
    "# constraints we want to apply in the synthesis. The four sets are:\n",
    "#               1) Marginal statistics (mean, var, skew, kurt, range)\n",
    "#               2) Correlation of subbands (space, orientation, scale)\n",
    "#               3) Correlation of magnitude responses (sp, or, sc)\n",
    "#               4) Relative local phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image_mat = io.loadmat(\"synth-test/init_ref.mat\")\n",
    "#image = image_mat[\"im0\"]\n",
    "\n",
    "# analyse original image\n",
    "orig_data = ta.TextureAnalysis(image, resol_x, resol_y, num_depth, num_ori, num_neighbor)\n",
    "orig_data.analyse()\n",
    "\n",
    "# center index of auto correlation \n",
    "Na = orig_data.LR_CA.shape[0]\n",
    "la = int((Na -1)/2)\n",
    "p = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#orig_data.IM_MAR[4] = 255\n",
    "#orig_data.IM_MAR[5] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = np.random.normal(0, 1, resol_x * resol_y).reshape(resol_y, resol_x)\n",
    "im = im * np.sqrt(orig_data.IM_MAR[1])\n",
    "im = im + orig_data.IM_MAR[0]\n",
    "\n",
    "# iteration\n",
    "prev_im = np.array([])\n",
    "prev_dst = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-babadb22bf32>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    142\u001b[0m         '''\n\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 144\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_tmp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimag\u001b[0m \u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvar\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0m_tmp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreal\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1e-6\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    145\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Non- trivial imaginary part, CF_RCOU lev = {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mvar\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32mc:\\users\\iino_kaoru\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36mvar\u001b[1;34m(a, axis, dtype, out, ddof, keepdims)\u001b[0m\n\u001b[0;32m   3620\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3621\u001b[0m     return _methods._var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n\u001b[1;32m-> 3622\u001b[1;33m                          **kwargs)\n\u001b[0m\u001b[0;32m   3623\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3624\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\iino_kaoru\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\numpy\\core\\_methods.py\u001b[0m in \u001b[0;36m_var\u001b[1;34m(a, axis, dtype, out, ddof, keepdims)\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;31m# Note that x may not be inexact and that we need it to be an array,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m     \u001b[1;31m# not a scalar.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 202\u001b[1;33m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0marrmean\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    203\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloating\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minteger\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for it in range(0, iter):\n",
    "    print(it)\n",
    "\n",
    "    # ------------------------------------\n",
    "    # Create pyramids of each PCA channel\n",
    "    # steerable pyramid\n",
    "    _sp = steerable.SteerablePyramid(im, resol_x, resol_y, num_depth, num_ori, '', '', 0)\n",
    "    _sp.create_pyramids()\n",
    "\n",
    "    # subtract means from lowpass residuals\n",
    "    _sp.LR['s'] = _sp.LR['s'].real - np.mean(_sp.LR['s'].real.flatten())\n",
    "    \n",
    "    #get lo of LR\n",
    "    _lsp = steerable.SteerablePyramid(_sp.LR[\"s\"],_sp.LR[\"s\"].shape[1] ,_sp.LR[\"s\"].shape[0], 1, num_ori, '', '', 0)\n",
    "    _lsp.create_pyramids() \n",
    "    im = _lsp.L0[\"s\"].real # rec_im is partially reconstrucated image\n",
    "    vari = orig_data.LR_CA[la,la]\n",
    "   \n",
    "    # ------------------------------------\n",
    "    # Adjust lowpass residual and get initial image for coarse to fine\n",
    "    # modify central auto correlation\n",
    "    if cmask[1]:\n",
    "        if (vari/orig_data.IM_MAR[1]) > 1e-4:\n",
    "            im = sutils.mod_acorr(im, orig_data.LR_CA, num_neighbor)\n",
    "        else:\n",
    "            im = im * np.sqrt(orig_data.LR_MAR[1] / np.var(im,ddof=1))\n",
    "            \n",
    "    # modify skewness of lowpass residual & modify kurtosis of lowpass residual\n",
    "    if cmask[0]:\n",
    "        if (vari/orig_data.IM_MAR[1]) > 1e-4  :\n",
    "            im = sutils.mod_skew(im, orig_data.LR_MAR[2])\n",
    "            im = sutils.mod_kurt(im, orig_data.LR_MAR[3])\n",
    "            \n",
    "    rec_im = im\n",
    "#    Pdb().set_trace()#############################################################################################\n",
    "\n",
    "    ## get original statistics of bandpass signals.\n",
    "    # create parents\n",
    "    if cmask[2]:\n",
    "        bnd = copy.deepcopy(_sp.BND)\n",
    "        _b_m, _, _ = sutils.trans_b(_sp.BND) # return magnitude,real,imag\n",
    "        for i in range(len(_b_m)):\n",
    "            for k in range(len(_b_m[i])):\n",
    "                _b_m[i][k] -= np.mean(_b_m[i][k])\n",
    "        ## magnitude\n",
    "        bnd_m = _b_m\n",
    "\n",
    "    ## maginitude of parent bandpass  (this is 'parent' in textureColorAnalysis.m)\n",
    "    ## real values of parent bandpass (this is half of 'rparent' in textureColorAnalysis.m)\n",
    "    ## imaginary values of parent bandpass (this is half of 'rparent' in textureColorAnalysis.m)\n",
    "\n",
    "    # ------------------------------------\n",
    "    # Coarse to fine adjustment\n",
    "    for dp in range(num_depth-1, -1, -1):\n",
    "        \n",
    "        if (cmask[2] or cmask[3]):\n",
    "            bnd_p, bnd_rp, bnd_ip = sutils.get_parent_g(_sp.BND)\n",
    "\n",
    "        if cmask[2]:\n",
    "            # combine orientations\n",
    "            cousins = sutils.cori_b(bnd_m, dp)\n",
    "            # adjust covariances\n",
    "            \n",
    "            if dp < num_depth-1:\n",
    "                parents = bnd_p[dp]\n",
    "                _tmp = sutils.adjust_corr2s(cousins, orig_data.CF_COUS[dp], parents, orig_data.CF_CPAR[dp])\n",
    "\n",
    "            else: # dp = 4 no pair．\n",
    "                _tmp = sutils.adjust_corr1(cousins, orig_data.CF_COUS[dp])\n",
    "\n",
    "            if ( np.var(_tmp.flatten().imag ) / np.var( _tmp.flatten().real) ) > 1e-6:\n",
    "                # non update cousins (bnd_magnitude) \n",
    "                print(\"Non- trivial imaginary part, mag cross Corr lev = {}\".format(dp))\n",
    "            else: \n",
    "                cousins = _tmp.real\n",
    "                bnd_m[dp] = np.array([ci.reshape( bnd_m[dp][0].shape[0],bnd_m[dp][0].shape[1] ) for ci in  cousins.T])\n",
    "            \n",
    "  #      Pdb().set_trace()###############################################################################################\n",
    "        # separate orientations\n",
    "        #cousins=[K][Y*X] to [K][Y,X] \n",
    "        #cousins = sutils.sori_b(cousins, num_ori) # [K][Y,X]にするやつ sqrt使ってるからダメ．\n",
    "        #bnd_m[dp] = np.array([ci.reshape( bnd_m[dp][0].shape[0],bnd_m[dp][0].shape[1] ) for ci in  cousins.T])\n",
    "\n",
    "        # adjust central auto corr. and update bandpass.\n",
    "        bnd_r = []\n",
    "        for k in range(num_ori):\n",
    "            # adjust central auto-correlations\n",
    "            _tmp = sutils.mod_acorr(bnd_m[dp][k], orig_data.BND_MCOR[dp][k], num_neighbor)\n",
    "\n",
    "            # update BND_N\n",
    "            bnd_m[dp][k] = _tmp\n",
    "            _mean = orig_data.BND_MMAR[dp][k][0]\n",
    "            bnd_m[dp][k] = bnd_m[dp][k] + _mean\n",
    "            \n",
    "            _idx = np.where(bnd_m[dp][k] < 0)\n",
    "            bnd_m[dp][k][_idx] = 0\n",
    "            \n",
    "            #_bnd = _sp.BND[dp][k]['s']\n",
    "            _idx1 = np.where(np.abs(_sp.BND[dp][k][\"s\"] ) < 10**(-12))\n",
    "            _idx2 = np.where(np.abs(_sp.BND[dp][k][\"s\"] ) >= 10**(-12))\n",
    "            _sp.BND[dp][k][\"s\"][_idx1] = _sp.BND[dp][k][\"s\"][_idx1] * bnd_m[dp][k][_idx1]\n",
    "            _sp.BND[dp][k][\"s\"][_idx2] = _sp.BND[dp][k][\"s\"][_idx2] * bnd_m[dp][k][_idx2] / np.abs(_sp.BND[dp][k][\"s\"][_idx2])\n",
    "            \n",
    "            bnd_r.append(_sp.BND[dp][k][\"s\"].real)\n",
    "            \n",
    "  #      Pdb().set_trace()#######################################################################################################\n",
    "        # combine orientations & make rcousins\n",
    "        rcousins = sutils.cori_bc(bnd_r, dp)\n",
    "\n",
    "        # adjust cross-correlation of real values of B and real/imaginary values of parents    \n",
    "        # when cmask[3] == 1 only use real part co\n",
    "        \n",
    "        if (dp < num_depth-1) & cmask[3]: #\n",
    "        # deform for optimization\n",
    "            rparents = sutils.cori_rp(bnd_rp, bnd_ip, dp)\n",
    "            \n",
    "            #size = _sp.BND[dp][0][\"s\"].shape\n",
    "            #rcousins = [ci.reshape( size[0],size[1] ).T.flatten() for ci in  rcousins.T]\n",
    "            #rcousins = np.array(rcousins).T\n",
    "            \n",
    "            _tmp = np.zeros_like(rcousins)\n",
    "            for k in range(num_ori):\n",
    "                cou = rcousins[:,k].reshape(-1,1)\n",
    "                _mean = np.mean(cou.flatten()**2).reshape(1,1)\n",
    "                Cxy = orig_data.CF_RPAR[dp][k].reshape(1,-1)\n",
    "                #_tmp = sutils.adjust_corr2(cou, orig_data.CF_RCOU[dp], rparents, orig_data.CF_RPAR[dp][k])\n",
    "                cou = sutils.adjust_corr2s(cou,_mean , rparents, Cxy)\n",
    "                _tmp[:,k] = cou.flatten()\n",
    "                \n",
    "            #_tmp = [ci.reshape( size[0],size[1] ).T.flatten() for ci in  _tmp.T]\n",
    "           # _tmp = np.array(_tmp).T\n",
    "            \n",
    "        else:\n",
    "            #_tmp = sutils.adjust_corr1(rcousins, orig_data.CF_RCOU[dp])\n",
    "            _tmp = rcousins\n",
    "            \n",
    "        ''' matlab Code で最下層のみでの更新はない．したほうがいいんじゃね？\n",
    "        else:\n",
    "            rcousins = sutils.adjust_corr1(_prev, orig_data.CF_RCOU[dp])\n",
    "            if np.isnan(rcousins).any():\n",
    "                rcousins = _prev\n",
    "        '''\n",
    "\n",
    "        if ( np.var(_tmp.flatten().imag ) / np.var( _tmp.flatten().real) ) > 1e-6:\n",
    "            print(\"Non- trivial imaginary part, CF_RCOU lev = {}\".format(dp))\n",
    "        else:\n",
    "            rcousins = _tmp\n",
    "            # [K,Y*X] => [K,Y,X]\n",
    "            # This sets real part only - signal is now nonanalytic!\n",
    "            size = _sp.BND[dp][0][\"s\"].shape\n",
    "            rcousins = [ci.reshape( size[0],size[1] ) for ci in  rcousins.T]\n",
    "            rcousins = np.array(rcousins)\n",
    "            for k in range(num_ori):\n",
    "                _sp.BND[dp][k][\"s\"] = rcousins[k]\n",
    "            \n",
    "  #      Pdb().set_trace()################################################################################################################\n",
    "        # Re-create analytic subbands\n",
    "        dims = np.asarray(_sp.BND[dp][0][\"s\"].shape,\"float\")\n",
    "        ctr = np.ceil((dims + 0.5)/2).astype(\"int\")\n",
    "        ang = sutils.mkAngle(dims,0,ctr)\n",
    "        ang[ctr[0]-1,ctr[1]-1] = -np.pi/2\n",
    "        \n",
    "        for k in range(num_ori): \n",
    "            ang0 = np.pi*(k-1 + 1)/num_ori\n",
    "            xang = (ang-ang0 + np.pi)%(2*np.pi) - np.pi\n",
    "            amask = abs( abs(xang) - np.pi/2 ) < 1e-10\n",
    "            amask = amask + 2* ( abs(xang) < (np.pi/2) )\n",
    "            amask[ctr[0]-1,ctr[1]-1] = 1\n",
    "            amask[:,0] = 1\n",
    "            amask[0,:] = 1        \n",
    "            amask = np.fft.fftshift(amask)\n",
    "            _sp.BND[dp][k][\"s\"] = np.fft.ifft2(amask * np.fft.fft2( _sp.BND[dp][k][\"s\"] ) )\n",
    "\n",
    "    #    Pdb().set_trace()#######################################################################################################\n",
    "        # same size\n",
    "        _z = np.zeros_like(_sp.BND[dp][0][\"s\"].real)\n",
    "        _s = steerable.SteerablePyramid(_z, _z.shape[1], _z.shape[0], 1, num_ori, '', '', 0)#create_filt_only\n",
    "        _recon = np.zeros_like(_z,dtype=np.complex128)\n",
    "        \n",
    "        for k in range(num_ori):\n",
    "            _recon = _recon + ( (1j)**(num_ori-1) ) * _s.B_FILT[0][k] * np.fft.fftshift( np.fft.fft2( _sp.BND[dp][k]['s'].real ) )\n",
    "\n",
    "        _recon = _recon * _s.L0_FILT\n",
    "        _recon = np.fft.ifft2(np.fft.ifftshift(_recon)).real\n",
    "\n",
    "        # expand image created before and sum up\n",
    "        _im = rec_im\n",
    "        _im = sutils.expand(_im, 2).real / 4.\n",
    "        _im = _im.real + _recon\n",
    "        \n",
    "        vari = orig_data.CF_CA[dp][la,la]\n",
    "        \n",
    "        #Pdb().set_trace()#########################################################################################################\n",
    "        # adjust auto-correlation\n",
    "        if cmask[1]:\n",
    "            if (vari/orig_data.IM_MAR[1]) > 1e-4:            \n",
    "                _im = sutils.mod_acorr(_im, orig_data.CF_CA[dp], num_neighbor)\n",
    "            else:\n",
    "                _im = im * np.sqrt( vari / np.var(_im.flatten() ,ddof=1) )\n",
    "            \n",
    "        _im = _im.real\n",
    "        \n",
    "        if cmask[0]:\n",
    "        # modify skewness and kurtosis\n",
    "            if (vari/orig_data.IM_MAR[1]) > 1e-4: \n",
    "                _im = sutils.mod_skew(_im, orig_data.CF_MAR[dp][2])\n",
    "                _im = sutils.mod_kurt(_im, orig_data.CF_MAR[dp][3])\n",
    "            \n",
    "        rec_im = _im\n",
    "\n",
    "    # end of coarse to fine\n",
    "  #      Pdb().set_trace()#################################################################################################333333333333333333333\n",
    "\n",
    "    # ------------------------------------\n",
    "    # Adjustment variance in H0 and final adjustment of coarse to fine.\n",
    "    if cmask[1] or cmask[2] or cmask[3]:\n",
    "        _tmp = _sp.H0['s'].real\n",
    "        vHPR = np.mean(_tmp.flatten()**2)\n",
    "        \n",
    "        if vHPR > orig_data.H0_PRO:\n",
    "            _tmp = _tmp * np.sqrt(orig_data.H0_PRO / vHPR)\n",
    "            _sp.H0[\"s\"] = _tmp\n",
    "\n",
    "    # recon H0\n",
    "    _recon = np.fft.fftshift(np.fft.fft2(_sp.H0[\"s\"]))\n",
    "    _recon = _recon * _s.H0_FILT\n",
    "    _recon = np.fft.ifft2(np.fft.ifftshift(_recon)).real\n",
    "\n",
    "    ## this is final data of coarse to fine.\n",
    "    rec_im = rec_im + _recon\n",
    "\n",
    "    # adjust skewness and kurtosis to original.\n",
    "    _mean = np.mean(rec_im)\n",
    "    _var = np.var(rec_im,ddof=1)\n",
    "    rec_im = rec_im - _mean\n",
    "    \n",
    "    if cmask[0]:\n",
    "        rec_im = rec_im * np.sqrt(( (1-p)*_var + p*orig_data.IM_MAR[1] )/_var)\n",
    "        \n",
    "    rec_im = rec_im + orig_data.IM_MAR[0]\n",
    "    \n",
    "    if cmask[0]:\n",
    "        rec_im = sutils.mod_skew(rec_im, orig_data.IM_MAR[2])\n",
    "        rec_im = sutils.mod_kurt(rec_im, orig_data.IM_MAR[3])\n",
    "    \n",
    "    _idx  = np.where(rec_im > orig_data.IM_MAR[4])\n",
    "    rec_im[_idx] = orig_data.IM_MAR[4]\n",
    "    _idx  = np.where(rec_im < orig_data.IM_MAR[5])\n",
    "    rec_im[_idx] = orig_data.IM_MAR[5]\n",
    "    im = rec_im\n",
    "    \n",
    " #   Pdb().set_trace()######################################################################################\n",
    "\n",
    "    # ------------------------------------\n",
    "    # Save image\n",
    "    _o_img = Image.fromarray(np.uint8(im)).convert('L')\n",
    "    _o_img.save(out_path + '/out-n{}-k{}-m{}-{}.png'.format(str(num_depth), str(num_ori), str(num_neighbor), str(it)))\n",
    "\n",
    "    if it > 0:\n",
    "            dst = np.sqrt(np.sum((prev_im - im)**2))\n",
    "            rt = np.sqrt(np.sum((prev_im - im)**2)) / np.sqrt(np.sum(prev_im**2))\n",
    "\n",
    "            prev_dst = dst\n",
    "            # acceleration\n",
    "            im = im + ALPHA * (im - prev_im)\n",
    "    prev_im = im\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
